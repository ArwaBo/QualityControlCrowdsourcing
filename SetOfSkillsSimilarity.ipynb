{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the tasks Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "task_df =  pd.read_csv('C:/Users/Arwa/Desktop/datasets/Ex2/Jobs_dataset_tokenized_Ex2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wordpress Expert install theme\n",
      "install wordpress theme plugins two\n"
     ]
    }
   ],
   "source": [
    "task1 = task_df.loc[52]\n",
    "task2 = task_df.loc[53]\n",
    "\n",
    "print(task1.loc['Job_Title'])\n",
    "print(task2.loc['Job_Title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute the simiality between titles using the cosine similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wordpress Expert install theme', 'install wordpress theme plugins two']\n",
      "similarity of titles: 0.5101490193104813\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "if task1.loc['Job_Title']!= '' and task2.loc['Job_Title']!= '':\n",
    "    data = [\n",
    "        task1.loc['Job_Title'],\n",
    "        task2.loc['Job_Title']\n",
    "            ]\n",
    "    print(data)\n",
    "\n",
    "    # Vectorise the data\n",
    "    vec = TfidfVectorizer()\n",
    "\n",
    "    X = vec.fit_transform(data)  # `X` will now be a TF-IDF representation of the data, the first row of `X` corresponds to the first sentence in `data`\n",
    "\n",
    "    # Calculate the pairwise cosine similarities (depending on the amount of data that you are going to have this could take a while)\n",
    "    S = cosine_similarity(X)\n",
    "    Title_Sim = S[1,0]\n",
    "else:\n",
    "    Title_Sim = 0\n",
    "print('similarity of titles:', Title_Sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the concept similairty method -- Taxonomy based simialrity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ete3 import TreeNode,Tree\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def concept_similarity_measure_ex2(C1, C2):\n",
    "    \n",
    "    taxonomy = Tree(\"skills_small_taxonomy_tree_level_score.nw\")\n",
    "    # print(\"C1\",C1,\"\\n\",\"C2\",C2)\n",
    "    \n",
    "\n",
    "    N1 = 0 # the distance from Concept 1 to the least common subsumer\n",
    "    N2 = 0 # the distance from Concept 2 to the least common subsumer\n",
    "    N = 0  # the distance from  the least common subsumer to the root\n",
    "    \"\"\" -----------------L   he shortest path between the tow concepts------------------------------\"\"\"\n",
    "\n",
    "\n",
    "    node1 = taxonomy.search_nodes(name=C1)\n",
    "    node2 = taxonomy.search_nodes(name=C2)\n",
    "    # print('node1', node1)\n",
    "    # print('node2', node2)\n",
    "    # if the skill is not found in the taxonomy\n",
    "    if node1 == [] or node2 == []:\n",
    "        # print('skills not in taxonomy')\n",
    "        # print(C1, C2)\n",
    "        data = [C1, C2]\n",
    "\n",
    "        # Vectorise the data\n",
    "        vec = TfidfVectorizer()\n",
    "\n",
    "        X = vec.fit_transform(\n",
    "            data)  # `X` will now be a TF-IDF representation of the data, the first row of `X` corresponds to the first sentence in `data`\n",
    "\n",
    "        # Calculate the pairwise cosine similarities (depending on the amount of data that you are going to have this could take a while)\n",
    "        S = cosine_similarity(X)\n",
    "        similarity = S[0, 1]\n",
    "\n",
    "\n",
    "        # print('simmmms',similarity)\n",
    "        l1 = l2 = 1.0  # how much should it be\n",
    "\n",
    "    else:\n",
    "        node1 = node1[0]\n",
    "        node2 = node2[0]\n",
    "        common = node1.get_common_ancestor(node2)\n",
    "        # print(common.is_root())\n",
    "        # print(\"common is \",common.name)\n",
    "\n",
    "        \"\"\" ------------------N the distance from root node to the least common subsumer-------------------\"\"\"\n",
    "        root = taxonomy.get_tree_root()\n",
    "        N = taxonomy.get_distance(common, root, topology_only=False)\n",
    "        # print(\"N = the distance between the common ancestor\", common.name, \"AND  ROOT IS \", N)\n",
    "\n",
    "        \"\"\" ----------------N1 the distance from Concept 1 to the least common subsumer--------------------\"\"\"\n",
    "        N1 = taxonomy.get_distance(C1, common, topology_only=False)\n",
    "        # print(\"N1 = the distance between\",C1,\"AND  ROOT IS \",N1)\n",
    "\n",
    "        \"\"\" ----------------N1 the distance from Concept 2 to the least common subsumer--------------------\"\"\"\n",
    "        N2 = taxonomy.get_distance(C2, common, topology_only=False)\n",
    "        # print(\"N2 = the distance between\",C2, \"AND  ROOT IS \", N2)\n",
    "\n",
    "        \"\"\" -------------------------------COMPUTE THE MEASURE FORMULA----------------------------------------\"\"\"\n",
    "\n",
    "        similarity = (2*N)/(N1+N2+(2*N))\n",
    "\n",
    "        \n",
    "        l1 = node1.level_score\n",
    "        l2 = node2.level_score\n",
    "        similarity = round(similarity, 2)\n",
    "        print(\"similarity between \", C1,\"and\",C2, \"is\", similarity)\n",
    "        print(\"level score  \",C1,'  is', l1)\n",
    "        print(\"level score  \",C2,'  is', l2)\n",
    "        print(\"---------------------------------------------------\")\n",
    "    return similarity,l1,l2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set of skills similarity between the 2 tasks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def is_nan(x):\n",
    "    return (x is np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required_Skills 1             Plgin\n",
      "Required_Skills 2    Website Design\n",
      "Required_Skills 3         WordPress\n",
      "Required_Skills 4               NaN\n",
      "Required_Skills 5               NaN\n",
      "Name: 52, dtype: object\n",
      "Required_Skills 1        Plgin\n",
      "Required_Skills 2    WordPress\n",
      "Required_Skills 3          NaN\n",
      "Required_Skills 4          NaN\n",
      "Required_Skills 5          NaN\n",
      "Name: 53, dtype: object\n"
     ]
    }
   ],
   "source": [
    "skills_t1 = task1.loc['Required_Skills 1':'Required_Skills 5']\n",
    "skills_t2 = task2.loc['Required_Skills 1':'Required_Skills 5']\n",
    "\n",
    "\n",
    "# skills_t1.sort()\n",
    "# skills_t2.sort()\n",
    "print(skills_t1)\n",
    "print(skills_t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute the similairty among the 2 sets of tasks using the concept similaity method--taxonomy based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s1 Plgin\n",
      "s2 Plgin\n",
      "similarity between  Plgin and Plgin is 1.0\n",
      "level score   Plgin   is 1.0\n",
      "level score   Plgin   is 1.0\n",
      "---------------------------------------------------\n",
      "s1 Plgin\n",
      "s2 WordPress\n",
      "similarity between  Plgin and WordPress is 0.91\n",
      "level score   Plgin   is 1.0\n",
      "level score   WordPress   is 0.8\n",
      "---------------------------------------------------\n",
      "sim_list of round # 0 is   [1.0, 0.91]\n",
      "____________________________________________________________________________________________\n",
      "s1 Website Design\n",
      "s2 Plgin\n",
      "similarity between  Website Design and Plgin is 0.67\n",
      "level score   Website Design   is 0.5\n",
      "level score   Plgin   is 1.0\n",
      "---------------------------------------------------\n",
      "s1 Website Design\n",
      "s2 WordPress\n",
      "similarity between  Website Design and WordPress is 0.75\n",
      "level score   Website Design   is 0.5\n",
      "level score   WordPress   is 0.8\n",
      "---------------------------------------------------\n",
      "sim_list of round # 1 is   [0.67, 0.75]\n",
      "____________________________________________________________________________________________\n",
      "s1 WordPress\n",
      "s2 Plgin\n",
      "similarity between  WordPress and Plgin is 0.91\n",
      "level score   WordPress   is 0.8\n",
      "level score   Plgin   is 1.0\n",
      "---------------------------------------------------\n",
      "s1 WordPress\n",
      "s2 WordPress\n",
      "similarity between  WordPress and WordPress is 1.0\n",
      "level score   WordPress   is 0.8\n",
      "level score   WordPress   is 0.8\n",
      "---------------------------------------------------\n",
      "sim_list of round # 2 is   [0.91, 1.0]\n",
      "____________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i = 0\n",
    "import pandas as pd  \n",
    "\n",
    "sim_df = pd.DataFrame()\n",
    "\n",
    "for s1 in skills_t1:\n",
    "    \n",
    "    sim_list = []\n",
    "    if not is_nan(s1):\n",
    "        \n",
    "        for s2 in skills_t2:\n",
    "            \n",
    "            if not is_nan(s2):\n",
    "                print(\"s1\", s1)\n",
    "                print(\"s2\",s2)\n",
    "                sim ,l1, l2 = concept_similarity_measure_ex2(s1, s2) # this function returns a tuple (sim, l1,l2)\n",
    "                sim = float(sim)  # convert to floats\n",
    "                sim_df.loc[s1,s2] = sim\n",
    "            \n",
    "                sim_list.append(sim)\n",
    "        print('sim_list of round #',i, \"is  \", sim_list)\n",
    "        print(\"____________________________________________________________________________________________\")\n",
    "        i = i + 1 \n",
    "       \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we have the similaity matix M "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plgin</th>\n",
       "      <th>WordPress</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Plgin</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Website Design</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WordPress</th>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Plgin  WordPress\n",
       "Plgin            1.00       0.91\n",
       "Website Design   0.67       0.75\n",
       "WordPress        0.91       1.00"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## construct the similarity vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plgin</th>\n",
       "      <th>Website Design</th>\n",
       "      <th>WordPress</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Plgin  Website Design  WordPress\n",
       "t1    0.0             0.0        0.0\n",
       "t2    0.0             0.0        0.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sim_vec_df = pd.DataFrame()\n",
    "\n",
    "for s in skills_t1:\n",
    "    if not is_nan(s):\n",
    "        sim_vec_df.loc['t1', s] = 0.0\n",
    "for s in skills_t2:\n",
    "    if not is_nan(s):\n",
    "        sim_vec_df.loc['t1', s] = 0.0\n",
    "for s in skills_t1:\n",
    "    if not is_nan(s):\n",
    "        sim_vec_df.loc['t2', s] = 0.0\n",
    "for s in skills_t2:\n",
    "    if not is_nan(s):\n",
    "        sim_vec_df.loc['t2', s] = 0.0\n",
    "\n",
    "\n",
    "sim_vec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plgin</th>\n",
       "      <th>Website Design</th>\n",
       "      <th>WordPress</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Plgin  Website Design  WordPress\n",
       "t1    1.0            1.00        1.0\n",
       "t2    1.0            0.75        1.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the skills of t1 to 1 in v1\n",
    "for skill in skills_t1:\n",
    "    if not is_nan(skill):\n",
    "        sim_vec_df.loc['t1', skill] = 1.0\n",
    "\n",
    "# set the skills of t2 to 1 in v2\n",
    "for skill in skills_t2:\n",
    "    if not is_nan(skill):\n",
    "        sim_vec_df.loc['t2', skill] = 1.0\n",
    "\n",
    "    # set the skills of t2 to the max in v1\n",
    "for skill in skills_t2:\n",
    "    if not is_nan(skill):\n",
    "        sim_vec_df.loc['t1', skill] = sim_df[skill].max()\n",
    "\n",
    "# set the skills of t1 to t2 in v2\n",
    "\n",
    "for skill in skills_t1:\n",
    "    if not is_nan(skill):\n",
    "        sim_vec_df.loc['t2', skill] = sim_df.loc[skill].max()\n",
    "\n",
    "sim_vec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "v1 = sim_vec_df.loc['t1'].values\n",
    "v1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1= v1.reshape(1, -1)\n",
    "v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.  , 0.75, 1.  ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2 = sim_vec_df.loc['t2'].as_matrix()\n",
    "v2=v2.reshape(1, -1)\n",
    "v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94839793]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill_similarity = cosine_similarity(v1,v2)\n",
    "skill_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X   (0, 0)\t0.4992213265230509\n",
      "  (0, 2)\t0.4992213265230509\n",
      "  (0, 3)\t0.4992213265230509\n",
      "  (0, 7)\t0.35520008546852583\n",
      "  (0, 4)\t0.35520008546852583\n",
      "  (1, 7)\t0.35520008546852583\n",
      "  (1, 4)\t0.35520008546852583\n",
      "  (1, 6)\t0.4992213265230509\n",
      "  (1, 1)\t0.4992213265230509\n",
      "  (1, 5)\t0.4992213265230509\n",
      "similarity of skills: 0.25233420143369617\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "data =['CSS HTML PHP WordPress Plgin','Plgin Website Design WordPress SQL'] \n",
    "  \n",
    "   \n",
    "# Vectorise the data\n",
    "vec = TfidfVectorizer()\n",
    "\n",
    "\"\"\"`X` will now be a TF-IDF representation of the data, the first row \n",
    "of `X` corresponds to the first sentence in `data`\"\"\" \n",
    "\n",
    "X = vec.fit_transform(data)  \n",
    "\n",
    "print(\"X\", X)\n",
    "# Calculate the pairwise cosine similarities (depending on the amount of data that you are going to have this could take a while)\n",
    "S = cosine_similarity(X)\n",
    "Skills_Sim = S[1,0]\n",
    "\n",
    "print('similarity of skills:', Skills_Sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Matrix factorozation Using SVD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import svd\n",
    "\n",
    "\n",
    "U, S, V = svd(sim_df, full_matrices=False)\n",
    "U.shape, S.shape, V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55, 0.75, 0.6 , 0.25],\n",
       "       [0.6 , 0.86, 0.67, 0.29],\n",
       "       [0.8 , 0.86, 0.89, 0.29],\n",
       "       [0.91, 0.75, 1.  , 0.25],\n",
       "       [1.  , 0.67, 0.91, 0.22]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reconstructing the original matrix \n",
    "np.dot(U.dot(np.diag(S)), V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U contain information on how your words are related to each other \n",
      "[[-0.35826264 -0.44665345  0.2099729  -0.71208919]\n",
      " [-0.40211295 -0.57011472  0.17368125  0.30636737]\n",
      " [-0.4794394  -0.13167309 -0.28364323  0.54110332]\n",
      " [-0.49820434  0.34548079 -0.64831706 -0.31933139]\n",
      " [-0.48154268  0.58204393  0.65190315  0.06559481]]\n",
      "\n",
      "\n",
      "\n",
      "S  contains information on how much information from the underlying table is contained in each column\n",
      "[3.13049790e+00 3.83341068e-01 8.61764853e-02 2.47361447e-03]\n",
      "\n",
      "\n",
      "\n",
      "V  \n",
      "[[-0.56117986 -0.55042965 -0.59015612 -0.18390248]\n",
      " [ 0.53050603 -0.7550654   0.28168854 -0.26285199]\n",
      " [ 0.63490512  0.15607151 -0.75632563  0.02255465]\n",
      " [ 0.02315199 -0.3202267  -0.01840796  0.94687908]]\n"
     ]
    }
   ],
   "source": [
    "print(\"U contain information on how your words are related to each other \")\n",
    "print(U)\n",
    "print(\"\\n\\n\")\n",
    "print(\"S  contains information on how much information from the underlying table is contained in each column\")\n",
    "print(S)\n",
    "print(\"\\n\\n\")\n",
    "print(\"V  \")\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variance of the training samples transformed by a projection to each component\n",
      "[0.02882949 0.0291032  0.00148209] \n",
      "\n",
      "Percentage of variance explained by each of the selected components.\n",
      "[0.4852142  0.48982098 0.02494428] \n",
      "\n",
      "0.999979461335971 \n",
      "\n",
      "The singular values corresponding to each of the selected components.\n",
      "[3.1304979  0.38334107 0.08617649]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.random_projection import sparse_random_matrix\n",
    "\n",
    "svd = TruncatedSVD(n_components=3)\n",
    "svd.fit(sim_df)  \n",
    "\n",
    "print(\"The variance of the training samples transformed by a projection to each component\")\n",
    "print(svd.explained_variance_,\"\\n\")  \n",
    "print(\"Percentage of variance explained by each of the selected components.\")\n",
    "print(svd.explained_variance_ratio_,\"\\n\") \n",
    "print(svd.explained_variance_ratio_.sum(),\"\\n\")  \n",
    "print(\"The singular values corresponding to each of the selected components.\")\n",
    "print(svd.singular_values_)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1304979029220643"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S[0] #highst singular value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn import linear_model\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA,TruncatedSVD\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.linalg import svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'explained_variance_ratio_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-a768bf4c31a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# List of explained variances\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtsvd_var_ratios\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'explained_variance_ratio_'"
     ]
    }
   ],
   "source": [
    "# List of explained variances\n",
    "tsvd_var_ratios = svd.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4852142 , 0.48982098])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function\n",
    "def select_n_components(var_ratio, goal_var: float) -> int:\n",
    "    # Set initial variance explained so far\n",
    "    total_variance = 0.0\n",
    "    \n",
    "    # Set initial number of features\n",
    "    n_components = 0\n",
    "    \n",
    "    # For the explained variance of each feature:\n",
    "    for explained_variance in var_ratio:\n",
    "        \n",
    "        # Add the explained variance to the total\n",
    "        total_variance += explained_variance\n",
    "        \n",
    "        # Add one to the number of components\n",
    "        n_components += 1\n",
    "        \n",
    "        # If we reach our goal level of explained variance\n",
    "        if total_variance >= goal_var:\n",
    "            # End the loop\n",
    "            break\n",
    "            \n",
    "    # Return the number of components\n",
    "    return n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tsvd_var_ratios' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-96e0fc92c272>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Run function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mno_components\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_n_components\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtsvd_var_ratios\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.99\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mno_components\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tsvd_var_ratios' is not defined"
     ]
    }
   ],
   "source": [
    "# Run function\n",
    "no_components = select_n_components(tsvd_var_ratios, 0.99)\n",
    "no_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'no_components' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-5246963dcf75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msvd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTruncatedSVD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mno_components\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msim_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msim_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'no_components' is not defined"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components = no_components)\n",
    "x = svd.fit(sim_df).transform(sim_df)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'fit_transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-c72a90675eaa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mU\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msim_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mVT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'fit_transform'"
     ]
    }
   ],
   "source": [
    "U = svd.fit_transform(sim_df)\n",
    "S = svd.explained_variance_ratio_\n",
    "VT = svd.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.35826264, -0.44665345,  0.2099729 , -0.71208919],\n",
       "       [-0.40211295, -0.57011472,  0.17368125,  0.30636737],\n",
       "       [-0.4794394 , -0.13167309, -0.28364323,  0.54110332],\n",
       "       [-0.49820434,  0.34548079, -0.64831706, -0.31933139],\n",
       "       [-0.48154268,  0.58204393,  0.65190315,  0.06559481]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.56117986,  0.55042965,  0.59015612,  0.18390248],\n",
       "       [ 0.53050603, -0.7550654 ,  0.28168854, -0.26285199]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2608948 , 0.36286226, 0.297531  , 0.12212213],\n",
       "       [0.28597501, 0.41702873, 0.33030935, 0.14046478],\n",
       "       [0.39556311, 0.41951881, 0.42281686, 0.14042579],\n",
       "       [0.45908895, 0.36755815, 0.46487595, 0.12211752],\n",
       "       [0.46845097, 0.32008831, 0.46245237, 0.10578759]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reconstructing the reduced matrix \n",
    "np.dot(U.dot(np.diag(S)), VT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.05204987e-31 1.00000000e+00]\n",
      "1.0000000000000002\n",
      "[1.22888121 0.69989355]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.random_projection import sparse_random_matrix\n",
    "\n",
    "svd = TruncatedSVD(n_components=no_components)\n",
    "svd.fit(X)  \n",
    "\n",
    "\n",
    "print(svd.explained_variance_ratio_)  \n",
    "\n",
    "print(svd.explained_variance_ratio_.sum())  \n",
    "\n",
    "print(svd.singular_values_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5000000000000001\n"
     ]
    }
   ],
   "source": [
    "print(svd.explained_variance_ratio_.sum()/no_components ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_algorithms():\n",
    "    svd_a = TruncatedSVD(30, algorithm=\"arpack\")\n",
    "    svd_r = TruncatedSVD(30, algorithm=\"randomized\", random_state=42)\n",
    " \n",
    "    Xa = svd_a.fit_transform(X)[:, :6]\n",
    "    Xr = svd_r.fit_transform(X)[:, :6]\n",
    "    assert_array_almost_equal(Xa, Xr, decimal=5)\n",
    " \n",
    "    comp_a = np.abs(svd_a.components_)\n",
    "    comp_r = np.abs(svd_r.components_)\n",
    "    # All elements are equal, but some elements are more equal than others.\n",
    "    assert_array_almost_equal(comp_a[:9], comp_r[:9])\n",
    "    assert_array_almost_equal(comp_a[9:], comp_r[9:], decimal=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "k must be between 1 and min(A.shape), k=30",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-126-7ed1cc331a7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_algorithms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-125-85e888cee2f4>\u001b[0m in \u001b[0;36mtest_algorithms\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0msvd_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTruncatedSVD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"randomized\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mXa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvd_a\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mXr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvd_r\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0massert_array_almost_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\decomposition\\truncated_svd.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"arpack\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m             \u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m             \u001b[1;31m# svds doesn't abide by scipy.linalg.svd/randomized_svd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[1;31m# conventions, so reverse its outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\scipy\\sparse\\linalg\\eigen\\arpack\\arpack.py\u001b[0m in \u001b[0;36msvds\u001b[1;34m(A, k, ncv, tol, which, v0, maxiter, return_singular_vectors)\u001b[0m\n\u001b[0;32m   1722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1723\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1724\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"k must be between 1 and min(A.shape), k=%d\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1725\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1726\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLinearOperator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: k must be between 1 and min(A.shape), k=30"
     ]
    }
   ],
   "source": [
    "test_algorithms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## then the total task similairty score can be found by "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n"
     ]
    }
   ],
   "source": [
    "C1 = 0.3\n",
    "C2 = 0.7\n",
    "task_2_task_similarity_score = C1*Title_Sim + C2*skills_sim\n",
    "task_2_task_similarity_score = round(task_2_task_similarity_score, 1)\n",
    "print(task_2_task_similarity_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s1 CSS\n",
      "s2 Plgin\n",
      "similarity between  CSS and Plgin is 0.55\n",
      "level score   CSS   is 0.8\n",
      "level score   Plgin   is 1.0\n",
      "---------------------------------------------------\n",
      "s1 CSS\n",
      "s2 Website Design\n",
      "similarity between  CSS and Website Design is 0.75\n",
      "level score   CSS   is 0.8\n",
      "level score   Website Design   is 0.5\n",
      "---------------------------------------------------\n",
      "s1 CSS\n",
      "s2 WordPress\n",
      "similarity between  CSS and WordPress is 0.6\n",
      "level score   CSS   is 0.8\n",
      "level score   WordPress   is 0.8\n",
      "---------------------------------------------------\n",
      "s1 CSS\n",
      "s2 SQL\n",
      "similarity between  CSS and SQL is 0.25\n",
      "level score   CSS   is 0.8\n",
      "level score   SQL   is 0.5\n",
      "---------------------------------------------------\n",
      "sim_list of round # 1 is   [0.55, 0.75, 0.6, 0.25]\n",
      "____________________________________________________________________\n",
      "s1 HTML\n",
      "s2 Plgin\n",
      "similarity between  HTML and Plgin is 0.6\n",
      "level score   HTML   is 0.7\n",
      "level score   Plgin   is 1.0\n",
      "---------------------------------------------------\n",
      "s1 HTML\n",
      "s2 Website Design\n",
      "similarity between  HTML and Website Design is 0.86\n",
      "level score   HTML   is 0.7\n",
      "level score   Website Design   is 0.5\n",
      "---------------------------------------------------\n",
      "s1 HTML\n",
      "s2 WordPress\n",
      "similarity between  HTML and WordPress is 0.67\n",
      "level score   HTML   is 0.7\n",
      "level score   WordPress   is 0.8\n",
      "---------------------------------------------------\n",
      "s1 HTML\n",
      "s2 SQL\n",
      "similarity between  HTML and SQL is 0.29\n",
      "level score   HTML   is 0.7\n",
      "level score   SQL   is 0.5\n",
      "---------------------------------------------------\n",
      "sim_list of round # 2 is   [0.6, 0.86, 0.67, 0.29]\n",
      "____________________________________________________________________\n",
      "s1 PHP\n",
      "s2 Plgin\n",
      "similarity between  PHP and Plgin is 0.8\n",
      "level score   PHP   is 0.7\n",
      "level score   Plgin   is 1.0\n",
      "---------------------------------------------------\n",
      "s1 PHP\n",
      "s2 Website Design\n",
      "similarity between  PHP and Website Design is 0.86\n",
      "level score   PHP   is 0.7\n",
      "level score   Website Design   is 0.5\n",
      "---------------------------------------------------\n",
      "s1 PHP\n",
      "s2 WordPress\n",
      "similarity between  PHP and WordPress is 0.89\n",
      "level score   PHP   is 0.7\n",
      "level score   WordPress   is 0.8\n",
      "---------------------------------------------------\n",
      "s1 PHP\n",
      "s2 SQL\n",
      "similarity between  PHP and SQL is 0.29\n",
      "level score   PHP   is 0.7\n",
      "level score   SQL   is 0.5\n",
      "---------------------------------------------------\n",
      "sim_list of round # 3 is   [0.8, 0.86, 0.89, 0.29]\n",
      "____________________________________________________________________\n",
      "s1 WordPress\n",
      "s2 Plgin\n",
      "similarity between  WordPress and Plgin is 0.91\n",
      "level score   WordPress   is 0.8\n",
      "level score   Plgin   is 1.0\n",
      "---------------------------------------------------\n",
      "s1 WordPress\n",
      "s2 Website Design\n",
      "similarity between  WordPress and Website Design is 0.75\n",
      "level score   WordPress   is 0.8\n",
      "level score   Website Design   is 0.5\n",
      "---------------------------------------------------\n",
      "s1 WordPress\n",
      "s2 WordPress\n",
      "similarity between  WordPress and WordPress is 1.0\n",
      "level score   WordPress   is 0.8\n",
      "level score   WordPress   is 0.8\n",
      "---------------------------------------------------\n",
      "s1 WordPress\n",
      "s2 SQL\n",
      "similarity between  WordPress and SQL is 0.25\n",
      "level score   WordPress   is 0.8\n",
      "level score   SQL   is 0.5\n",
      "---------------------------------------------------\n",
      "sim_list of round # 4 is   [0.91, 0.75, 1.0, 0.25]\n",
      "____________________________________________________________________\n",
      "s1 Plgin\n",
      "s2 Plgin\n",
      "similarity between  Plgin and Plgin is 1.0\n",
      "level score   Plgin   is 1.0\n",
      "level score   Plgin   is 1.0\n",
      "---------------------------------------------------\n",
      "s1 Plgin\n",
      "s2 Website Design\n",
      "similarity between  Plgin and Website Design is 0.67\n",
      "level score   Plgin   is 1.0\n",
      "level score   Website Design   is 0.5\n",
      "---------------------------------------------------\n",
      "s1 Plgin\n",
      "s2 WordPress\n",
      "similarity between  Plgin and WordPress is 0.91\n",
      "level score   Plgin   is 1.0\n",
      "level score   WordPress   is 0.8\n",
      "---------------------------------------------------\n",
      "s1 Plgin\n",
      "s2 SQL\n",
      "similarity between  Plgin and SQL is 0.22\n",
      "level score   Plgin   is 1.0\n",
      "level score   SQL   is 0.5\n",
      "---------------------------------------------------\n",
      "sim_list of round # 5 is   [1.0, 0.67, 0.91, 0.22]\n",
      "____________________________________________________________________\n",
      "total count of values > 0.8 =  7\n",
      "length of all the lists  20\n",
      "SKILLS SIM total count / total number of cells =  0.3\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "weight_list = []\n",
    "sim_max = []\n",
    "ave_list = [] \n",
    "i = 0\n",
    "import pandas as pd  \n",
    "scaler = 0 \n",
    "total_c = 0 \n",
    "sim_df = pd.DataFrame()\n",
    "ave = 0 \n",
    "for s1 in skills_t1:\n",
    "    i = i+1\n",
    "    sim_list = []\n",
    "    if not is_nan(s1):\n",
    "        \n",
    "        for s2 in skills_t2:\n",
    "            \n",
    "            if not is_nan(s2):\n",
    "                print(\"s1\", s1)\n",
    "                print(\"s2\",s2)\n",
    "                sim ,l1, l2 = concept_similarity_measure_ex2(s1, s2) # this function returns a tuple (sim, l1,l2)\n",
    "                sim = float(sim)  # convert to floats\n",
    "                l1 = float(l2)\n",
    "                l2 = float(l1)\n",
    "                sim_df.loc[s1,s2] = sim\n",
    "            \n",
    "                sim_list.append(sim)\n",
    "        print('sim_list of round #',i, \"is  \", sim_list)\n",
    "        sim_list = np.array(sim_list)\n",
    "        \n",
    "#         maxima = sim_list.argmax()\n",
    "#         print(\"argmax = \", maxima)\n",
    "                \n",
    "        for k in sim_list:\n",
    "            if k >= 0.8025:\n",
    "                total_c= total_c + 1 \n",
    "                \n",
    "        print(\"____________________________________________________________________\")\n",
    "\n",
    "        scaler = scaler + len(sim_list) \n",
    "        \n",
    "print(\"total count of values > 0.8 = \", total_c)\n",
    "skills_sim = round(total_c /scaler,1) \n",
    "print(\"length of all the lists \", scaler)\n",
    "print(\"SKILLS SIM total count / total number of cells = \", skills_sim)\n",
    "print(\"---------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3rd Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s1 CSS\n",
      "s2 Plgin\n",
      "similarity between  CSS and Plgin is 0.55\n",
      "level score   CSS   is 0.8\n",
      "level score   Plgin   is 1.0\n",
      "---------------------------------------------------\n",
      "s1 CSS\n",
      "s2 Website Design\n",
      "similarity between  CSS and Website Design is 0.75\n",
      "level score   CSS   is 0.8\n",
      "level score   Website Design   is 0.5\n",
      "---------------------------------------------------\n",
      "s1 CSS\n",
      "s2 WordPress\n",
      "similarity between  CSS and WordPress is 0.6\n",
      "level score   CSS   is 0.8\n",
      "level score   WordPress   is 0.8\n",
      "---------------------------------------------------\n",
      "s1 CSS\n",
      "s2 SQL\n",
      "similarity between  CSS and SQL is 0.25\n",
      "level score   CSS   is 0.8\n",
      "level score   SQL   is 0.5\n",
      "---------------------------------------------------\n",
      "sim_list of round # 1 is   [0.55, 0.75, 0.6, 0.25]\n",
      "________________________________________________________________\n",
      "s1 HTML\n",
      "s2 Plgin\n",
      "similarity between  HTML and Plgin is 0.6\n",
      "level score   HTML   is 0.7\n",
      "level score   Plgin   is 1.0\n",
      "---------------------------------------------------\n",
      "s1 HTML\n",
      "s2 Website Design\n",
      "similarity between  HTML and Website Design is 0.86\n",
      "level score   HTML   is 0.7\n",
      "level score   Website Design   is 0.5\n",
      "---------------------------------------------------\n",
      "s1 HTML\n",
      "s2 WordPress\n",
      "similarity between  HTML and WordPress is 0.67\n",
      "level score   HTML   is 0.7\n",
      "level score   WordPress   is 0.8\n",
      "---------------------------------------------------\n",
      "s1 HTML\n",
      "s2 SQL\n",
      "similarity between  HTML and SQL is 0.29\n",
      "level score   HTML   is 0.7\n",
      "level score   SQL   is 0.5\n",
      "---------------------------------------------------\n",
      "sim_list of round # 2 is   [0.6, 0.86, 0.67, 0.29]\n",
      "________________________________________________________________\n",
      "s1 PHP\n",
      "s2 Plgin\n",
      "similarity between  PHP and Plgin is 0.8\n",
      "level score   PHP   is 0.7\n",
      "level score   Plgin   is 1.0\n",
      "---------------------------------------------------\n",
      "s1 PHP\n",
      "s2 Website Design\n",
      "similarity between  PHP and Website Design is 0.86\n",
      "level score   PHP   is 0.7\n",
      "level score   Website Design   is 0.5\n",
      "---------------------------------------------------\n",
      "s1 PHP\n",
      "s2 WordPress\n",
      "similarity between  PHP and WordPress is 0.89\n",
      "level score   PHP   is 0.7\n",
      "level score   WordPress   is 0.8\n",
      "---------------------------------------------------\n",
      "s1 PHP\n",
      "s2 SQL\n",
      "similarity between  PHP and SQL is 0.29\n",
      "level score   PHP   is 0.7\n",
      "level score   SQL   is 0.5\n",
      "---------------------------------------------------\n",
      "sim_list of round # 3 is   [0.8, 0.86, 0.89, 0.29]\n",
      "________________________________________________________________\n",
      "s1 WordPress\n",
      "s2 Plgin\n",
      "similarity between  WordPress and Plgin is 0.91\n",
      "level score   WordPress   is 0.8\n",
      "level score   Plgin   is 1.0\n",
      "---------------------------------------------------\n",
      "s1 WordPress\n",
      "s2 Website Design\n",
      "similarity between  WordPress and Website Design is 0.75\n",
      "level score   WordPress   is 0.8\n",
      "level score   Website Design   is 0.5\n",
      "---------------------------------------------------\n",
      "s1 WordPress\n",
      "s2 WordPress\n",
      "similarity between  WordPress and WordPress is 1.0\n",
      "level score   WordPress   is 0.8\n",
      "level score   WordPress   is 0.8\n",
      "---------------------------------------------------\n",
      "s1 WordPress\n",
      "s2 SQL\n",
      "similarity between  WordPress and SQL is 0.25\n",
      "level score   WordPress   is 0.8\n",
      "level score   SQL   is 0.5\n",
      "---------------------------------------------------\n",
      "sim_list of round # 4 is   [0.91, 0.75, 1.0, 0.25]\n",
      "________________________________________________________________\n",
      "s1 Plgin\n",
      "s2 Plgin\n",
      "similarity between  Plgin and Plgin is 1.0\n",
      "level score   Plgin   is 1.0\n",
      "level score   Plgin   is 1.0\n",
      "---------------------------------------------------\n",
      "s1 Plgin\n",
      "s2 Website Design\n",
      "similarity between  Plgin and Website Design is 0.67\n",
      "level score   Plgin   is 1.0\n",
      "level score   Website Design   is 0.5\n",
      "---------------------------------------------------\n",
      "s1 Plgin\n",
      "s2 WordPress\n",
      "similarity between  Plgin and WordPress is 0.91\n",
      "level score   Plgin   is 1.0\n",
      "level score   WordPress   is 0.8\n",
      "---------------------------------------------------\n",
      "s1 Plgin\n",
      "s2 SQL\n",
      "similarity between  Plgin and SQL is 0.22\n",
      "level score   Plgin   is 1.0\n",
      "level score   SQL   is 0.5\n",
      "---------------------------------------------------\n",
      "sim_list of round # 5 is   [1.0, 0.67, 0.91, 0.22]\n",
      "________________________________________________________________\n",
      "total sum of values > 0.8 =  6.43\n",
      "length of all the lists  20\n",
      "SKILLS SIM total count /length of list =  0.3\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "weight_list = []\n",
    "sim_max = []\n",
    "ave_list = [] \n",
    "i = 0\n",
    "import pandas as pd  \n",
    "scaler = 0 \n",
    "total_valid_values = 0 \n",
    "sim_df = pd.DataFrame()\n",
    "ave = 0 \n",
    "for s1 in skills_t1:\n",
    "    c = 0 \n",
    "    j = 0 \n",
    "    i = i+1\n",
    "    sim_list = []\n",
    "    if not is_nan(s1):\n",
    "        for s2 in skills_t2:\n",
    "            \n",
    "            if not is_nan(s2):\n",
    "                print(\"s1\", s1)\n",
    "                print(\"s2\",s2)\n",
    "                sim ,l1, l2 = concept_similarity_measure_ex2(s1, s2) # this function returns a tuple (sim, l1,l2)\n",
    "                sim = float(sim)  # convert to floats\n",
    "\n",
    "                sim_df.loc[s1,s2] = sim\n",
    "            \n",
    "                sim_list.append(sim)\n",
    "        print('sim_list of round #',i, \"is  \", sim_list)\n",
    "        print(\"________________________________________________________________\")\n",
    "        sim_list = np.array(sim_list)\n",
    "        \n",
    "\n",
    "                \n",
    "        for k in sim_list:\n",
    "            if k >= 0.8025:\n",
    "                total_valid_values = total_valid_values + k \n",
    "\n",
    "        scaler = scaler + len(sim_list) \n",
    "\n",
    "print(\"total sum of values > 0.8 = \", total_valid_values)\n",
    "skills_sim = round(total_valid_values /scaler,1) \n",
    "print(\"length of all the lists \", scaler)\n",
    "print(\"SKILLS SIM total count /length of list = \", skills_sim)\n",
    "print(\"---------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
